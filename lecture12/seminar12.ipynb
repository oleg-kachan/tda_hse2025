{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import gudhi as gd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False, linewidth=100)\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gudhi_toarray(diagrams, replace_inf=True):\n",
    "    diagram = np.array([[birth, death, dim] for (dim, (birth, death)) in diagrams])\n",
    "    if replace_inf==True:\n",
    "        diagram = np.nan_to_num(diagram, posinf=-np.inf)\n",
    "        diagram = np.nan_to_num(diagram, neginf=np.max(diagram))\n",
    "    return diagram\n",
    "\n",
    "def diagram_reshape(diagram):\n",
    "    zero_idx = np.where(diagram[:,2]==0)\n",
    "    one_idx = np.where(diagram[:,2]==1)\n",
    "    return diagram[zero_idx], diagram[one_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d44be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagram(image, device, sublevel=True):\n",
    "    # get height and square image\n",
    "    h = int(np.sqrt(image.shape[0]))\n",
    "    image_sq = image.reshape((h,h))\n",
    "\n",
    "    # create complex\n",
    "    cmplx = gd.CubicalComplex(dimensions=(h, h), top_dimensional_cells=(sublevel*image))\n",
    "\n",
    "    # get pairs of critical simplices\n",
    "    cmplx.compute_persistence()\n",
    "    critical_pairs = cmplx.cofaces_of_persistence_pairs()\n",
    "    \n",
    "    # get essential critical pixel\n",
    "    bpx0_essential = critical_pairs[1][0][0] // h, critical_pairs[1][0][0] % h\n",
    "\n",
    "    # get critical pixels corresponding to critical simplices\n",
    "    try:\n",
    "        bpx0 = [critical_pairs[0][0][i][0] for i in range(len(critical_pairs[0][0]))]\n",
    "        dpx0 = [critical_pairs[0][0][i][1] for i in range(len(critical_pairs[0][0]))]\n",
    "    except IndexError:\n",
    "        bpx0 = []\n",
    "        dpx0 = []\n",
    "        \n",
    "    try:\n",
    "        bpx1 = [critical_pairs[0][1][i][0] for i in range(len(critical_pairs[0][1]))]\n",
    "        dpx1 = [critical_pairs[0][1][i][1] for i in range(len(critical_pairs[0][1]))]\n",
    "    except IndexError:\n",
    "        bpx1 = []\n",
    "        dpx1 = []\n",
    "    \n",
    "\n",
    "    flat_image = image_sq.flatten()\n",
    "    pd0_essential = torch.tensor([[image_sq[bpx0_essential], torch.max(image)]])\n",
    "\n",
    "    if (len(bpx0)!=0):\n",
    "        pdb0 = flat_image[bpx0][:, None]\n",
    "        pdd0 = flat_image[dpx0][:, None]\n",
    "        pd0 = torch.Tensor(torch.hstack([pdb0, pdd0]))\n",
    "        pd0 = torch.vstack([pd0, pd0_essential.to(device)])\n",
    "    else:\n",
    "        pd0 = pd0_essential\n",
    "\n",
    "    if (len(bpx1)!=0):\n",
    "        pdb1 = flat_image[bpx1][:, None]\n",
    "        pdd1 = flat_image[dpx1][:, None]\n",
    "        pd1 = torch.Tensor(torch.hstack([pdb1, pdd1]))\n",
    "    else:\n",
    "        pd1 = torch.zeros((1, 2))\n",
    "    \n",
    "    return pd0, pd1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8642419",
   "metadata": {},
   "source": [
    "# Seminar 12: Topological data analysis of digital images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c80c4f",
   "metadata": {},
   "source": [
    "#### Torch Dataset and collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, diagrams, y):\n",
    "        super().__init__()\n",
    "        \n",
    "        # get diagrams as list of tensors\n",
    "        D = torch.ones([len(diagrams), max(map(len, diagrams))+1, 3]) * torch.inf  \n",
    "        for i, dgm in enumerate(diagrams):\n",
    "            D[i,:len(dgm)] = dgm\n",
    "\n",
    "        # cut to the largest diagram accross all dataset\n",
    "        max_len = torch.argmax(D[:,:,0], axis=1).max()\n",
    "        D = D[:,:max_len+1] # leave at least one inf value!\n",
    "            \n",
    "        self.D = D\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.D[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # get len of a batch and len of each diagram in a batch\n",
    "    n_batch = len(batch)\n",
    "    d_lengths = [int(torch.argmax(D[:,0])) for D, y_ in batch]\n",
    "    \n",
    "    # set batch tensor to the max length of a diagram in a batch\n",
    "    Ds = torch.ones([n_batch, max(d_lengths), 3]) * 0.\n",
    "    D_masks = torch.zeros([n_batch, max(d_lengths)]).bool()\n",
    "    ys = torch.zeros(n_batch).long()\n",
    "    \n",
    "    # populate diagrams, their masks, and targets\n",
    "    for i, (D, y) in enumerate(batch):\n",
    "        Ds[i][:d_lengths[i]] = D[:d_lengths[i]]\n",
    "        D_masks[i][d_lengths[i]:] = True\n",
    "        ys[i] = y\n",
    "    \n",
    "    return Ds, D_masks, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99df879",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistentHomologyTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in=3, d_out=5, d_model=16, d_hidden=32, num_heads=2, num_layers=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.linear_in = nn.Linear(d_in, d_model)\n",
    "        self.ln = nn.LayerNorm(d_in)\n",
    "        el = nn.TransformerEncoderLayer(d_model, num_heads, d_hidden, dropout, batch_first=True, activation=F.gelu)\n",
    "        self.encoder = nn.TransformerEncoder(el, num_layers)\n",
    "        self.linear_out = nn.Linear(d_model, d_out)\n",
    "        \n",
    "    def _masked_mean(self, X, mask):\n",
    "        X_masked = X * ~mask.unsqueeze(-1)\n",
    "        n_masks = torch.sum(~mask, axis=1)\n",
    "        X_masked_mean = torch.sum(X_masked, axis=1) / n_masks.unsqueeze(-1)\n",
    "        return X_masked_mean\n",
    "        \n",
    "    def forward(self, X, mask):\n",
    "        X = self.linear_in(self.ln(X))\n",
    "        X = self.encoder(X, src_key_padding_mask=mask)\n",
    "        X = self._masked_mean(X, mask)\n",
    "        X = self.linear_out(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617427af",
   "metadata": {},
   "source": [
    "### Sublevel filtration\n",
    "\n",
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor(), Normalize(0.0, 1.0)])\n",
    "dataset = MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sublevel = []\n",
    "\n",
    "for image, y_ in tqdm(dataset):\n",
    "\n",
    "    # create cubical complex\n",
    "    cmplx = gd.CubicalComplex(dimensions=image.shape, top_dimensional_cells=image.flatten())\n",
    "\n",
    "    # get pairs of critical simplices\n",
    "    cmplx.compute_persistence()\n",
    "    X_sublevel.append(torch.tensor(gudhi_toarray(cmplx.persistence())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b118e",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cde487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_repeats = 1\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "history = np.zeros((n_repeats, n_epochs, 3))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for repeat_idx in range(n_repeats):\n",
    "    \n",
    "    # randomness\n",
    "    seed = repeat_idx\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # random state\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # data init\n",
    "    dataset = PersistenceDataset(X_sublevel, targets)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # model init\n",
    "    model = PersistentHomologyTransformer(d_in=3, d_out=10)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"{:3} {:6} {:6}\".format(repeat_idx, \"Loss\", \"Acc\"))\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        loss_epoch = []\n",
    "        for X, mask, y in dataloader:\n",
    "            loss_batch = criterion(model(X, mask), y)\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.append(loss_batch.detach())\n",
    "        \n",
    "        loss_epoch_mean = np.array(loss_epoch).mean()\n",
    "        history[repeat_idx,epoch_idx,0] = loss_epoch_mean\n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        for X, mask, y in dataloader:\n",
    "            y_hat = model(X, mask).argmax(dim=1)\n",
    "            correct += int((y_hat == y).sum())\n",
    "        accuracy_train = correct / len(dataloader.dataset)\n",
    "        history[repeat_idx,epoch_idx,1] = accuracy_train\n",
    "        \n",
    "        print(\"{:3} {:.4f} {:.4f}\".format(epoch_idx, loss_epoch_mean, accuracy_train))\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e62de0",
   "metadata": {},
   "source": [
    "### Direction filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e19a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "diagrams_all_dir = pickle.load(open(\"./data/MNIST_D_test_dir.pkl\", \"rb\"))\n",
    "targets = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = 0\n",
    "\n",
    "diagrams_dir = []\n",
    "for diagram_dir in diagrams_all_dir:\n",
    "    dir_idx = diagram_dir[:,-1] == direction\n",
    "    diagrams_dir.append(diagram_dir[dir_idx,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    # get len of a batch and len of each diagram in a batch\n",
    "    n_batch = len(batch)\n",
    "    d_lengths = [int(torch.argmax(D[:,0])) for D, y_ in batch]\n",
    "    \n",
    "    # set batch tensor to the max length of a diagram in a batch\n",
    "    Ds = torch.ones([n_batch, max(d_lengths), 3]) * 0.\n",
    "    D_masks = torch.zeros([n_batch, max(d_lengths)]).bool()\n",
    "    ys = torch.zeros(n_batch).long()\n",
    "    \n",
    "    # populate diagrams, their masks, and targets\n",
    "    for i, (D, y) in enumerate(batch):\n",
    "        Ds[i][:d_lengths[i]] = D[:d_lengths[i]]\n",
    "        D_masks[i][d_lengths[i]:] = True\n",
    "        ys[i] = y\n",
    "        \n",
    "    # masked normalize\n",
    "    for i, (D, y) in enumerate(batch):\n",
    "        Ds[i][~D_masks[i],0] = (Ds[i][~D_masks[i],0] - 1.0662154048380699) / 0.48181154844016033\n",
    "        Ds[i][~D_masks[i],1] = (Ds[i][~D_masks[i],1] - 1.4032599645792931) / 0.3154062619965701\n",
    "        Ds[i][~D_masks[i],2] = (Ds[i][~D_masks[i],2] - 0.7567565129537418) / 0.4290408990479055\n",
    "    \n",
    "    return Ds, D_masks, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70b0d0",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fca76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_repeats = 1\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "history = np.zeros((n_repeats, n_epochs, 3))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for repeat_idx in range(n_repeats):\n",
    "    \n",
    "    # randomness\n",
    "    seed = repeat_idx\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # random state\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # data init\n",
    "    dataset = PersistenceDataset(diagrams_dir, targets)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # model init\n",
    "    model = PersistentHomologyTransformer(d_in=3, d_out=10)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"{:3} {:6} {:6}\".format(repeat_idx, \"Loss\", \"Acc\"))\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        loss_epoch = []\n",
    "        for X, mask, y in dataloader:\n",
    "            loss_batch = criterion(model(X, mask), y)\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.append(loss_batch.detach())\n",
    "        \n",
    "        loss_epoch_mean = np.array(loss_epoch).mean()\n",
    "        history[repeat_idx,epoch_idx,0] = loss_epoch_mean\n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        for X, mask, y in dataloader:\n",
    "            y_hat = model(X, mask).argmax(dim=1)\n",
    "            correct += int((y_hat == y).sum())\n",
    "        accuracy_train = correct / len(dataloader.dataset)\n",
    "        history[repeat_idx,epoch_idx,1] = accuracy_train\n",
    "        \n",
    "        print(\"{:3} {:.4f} {:.4f}\".format(epoch_idx, loss_epoch_mean, accuracy_train))\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91e2e8",
   "metadata": {},
   "source": [
    "## Persistence Homology Transform\n",
    "\n",
    "### Direction filter\n",
    "\n",
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098245db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistenceTransformDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, diagrams, y, idx=None, eps=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # get diagrams as list of tensors\n",
    "        D = torch.ones([len(diagrams), max(map(len, diagrams))+1, 4]) * torch.inf\n",
    "\n",
    "        # select points according to eps and idx\n",
    "        for i, dgm in enumerate(diagrams):\n",
    "\n",
    "            # eps\n",
    "            if eps is not None:\n",
    "                eps_idx = (dgm[:,1] - dgm[:,0]) >= eps\n",
    "                dgm = dgm[eps_idx]\n",
    "\n",
    "            # idx\n",
    "            if idx is not None:\n",
    "                dgm_idx = torch.isin(dgm[:,-1], idx)\n",
    "                dgm = dgm[dgm_idx]\n",
    "                D[i,:len(dgm)] = dgm[:,:-1]\n",
    "            else:\n",
    "                D[i,:len(dgm)] = dgm[:,:-1]\n",
    "\n",
    "        # cut to the largest diagram accross all dataset\n",
    "        if idx is not None:\n",
    "            max_len = torch.argmax(D[:,:,0], axis=1).max()\n",
    "            D = D[:,:max_len+1] # leave at least one inf value!\n",
    "            \n",
    "        self.D = D\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.D[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "def collate_fn(batch):\n",
    "\n",
    "    # get len of a batch and len of each diagram in a batch\n",
    "    n_batch = len(batch)\n",
    "    d_lengths = [int(torch.argmax(D[:,0])) for D, y_ in batch]\n",
    "    \n",
    "    # set batch tensor to the max length of a diagram in a batch\n",
    "    Ds = torch.ones([n_batch, max(d_lengths), 4]) * 0.\n",
    "    D_masks = torch.zeros([n_batch, max(d_lengths)]).bool()\n",
    "    ys = torch.zeros(n_batch).long()\n",
    "    \n",
    "    # populate diagrams, their masks, and targets\n",
    "    for i, (D, y) in enumerate(batch):\n",
    "        Ds[i][:d_lengths[i]] = D[:d_lengths[i]]\n",
    "        D_masks[i][d_lengths[i]:] = True\n",
    "        ys[i] = y\n",
    "        \n",
    "    # masked normalize\n",
    "    for i, (D, y) in enumerate(batch):\n",
    "        Ds[i][~D_masks[i],0] = (Ds[i][~D_masks[i],0] - 1.0662154048380699) / 0.48181154844016033\n",
    "        Ds[i][~D_masks[i],1] = (Ds[i][~D_masks[i],1] - 1.4032599645792931) / 0.3154062619965701\n",
    "        Ds[i][~D_masks[i],2] = (Ds[i][~D_masks[i],2] - 0.7567565129537418) / 0.4290408990479055\n",
    "        Ds[i][~D_masks[i],3] = (Ds[i][~D_masks[i],3] - 11.803894241177744) / 11.236356222975049\n",
    "    \n",
    "    return Ds, D_masks, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e6809",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445939e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_repeats = 1\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "\n",
    "history = np.zeros((n_repeats, n_epochs, 3))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for repeat_idx in range(n_repeats):\n",
    "    \n",
    "    # randomness\n",
    "    seed = repeat_idx\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # random state\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # data init\n",
    "    dataset = PersistenceTransformDataset(diagrams_all_dir, targets, idx=torch.tensor([0, 3, 6]), eps=0.0)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # model init\n",
    "    model = PersistentHomologyTransformer(d_in=4, d_out=10) # increase input dim by 1\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"{:3} {:6} {:6}\".format(repeat_idx, \"Loss\", \"Acc\"))\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        loss_epoch = []\n",
    "        for X, mask, y in dataloader:\n",
    "            loss_batch = criterion(model(X, mask), y)\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.append(loss_batch.detach())\n",
    "        \n",
    "        loss_epoch_mean = np.array(loss_epoch).mean()\n",
    "        history[repeat_idx,epoch_idx,0] = loss_epoch_mean\n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        for X, mask, y in dataloader:\n",
    "            y_hat = model(X, mask).argmax(dim=1)\n",
    "            correct += int((y_hat == y).sum())\n",
    "        accuracy_train = correct / len(dataloader.dataset)\n",
    "        history[repeat_idx,epoch_idx,1] = accuracy_train\n",
    "        \n",
    "        print(\"{:3} {:.4f} {:.4f}\".format(epoch_idx, loss_epoch_mean, accuracy_train))\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c9782",
   "metadata": {},
   "source": [
    "### Convolutional filter\n",
    "\n",
    "#### Differentiability of persistent homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_diff = MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "dataloader_diff = DataLoader(dataset_diff, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56577d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(dataloader_diff))\n",
    "images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create complex\n",
    "cmplx = gd.CubicalComplex(dimensions=(28, 28), top_dimensional_cells=(images[0].flatten()))\n",
    "\n",
    "# reduce boundary matrix\n",
    "cmplx.compute_persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010506d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critical pixels\n",
    "critical_pairs = cmplx.cofaces_of_persistence_pairs()\n",
    "critical_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistence diagram\n",
    "pd = cmplx.persistence()\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12754c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_diagram(image):\n",
    "\n",
    "    h, w = image.shape\n",
    "    img_flat = image.flatten()\n",
    "\n",
    "    ccomplex = gd.CubicalComplex(\n",
    "        dimensions = (h, w), \n",
    "        top_dimensional_cells=img_flat\n",
    "    )\n",
    "    \n",
    "    # get pairs of critical simplices\n",
    "    ccomplex.compute_persistence()\n",
    "    critical_pairs = ccomplex.cofaces_of_persistence_pairs()\n",
    "\n",
    "    # get essential critical pixels (never vanish)\n",
    "    essential_features = critical_pairs[1][0]\n",
    "\n",
    "    # 0-homology image critical pixels\n",
    "    try:\n",
    "        critical_pairs_0 = critical_pairs[0][0]\n",
    "    except:\n",
    "        critical_pairs_0 = np.empty((0, 2))\n",
    "    critical_0_ver_ind = critical_pairs_0 // w\n",
    "    critical_0_hor_ind = critical_pairs_0 % w\n",
    "    critical_pixels_0 = np.stack([critical_0_ver_ind, critical_0_hor_ind], axis=2)\n",
    "\n",
    "    # 0-homology essential pixels (ends with last added pixel)\n",
    "    last_pixel = torch.argmax(image).item()\n",
    "    essential_pixels_0 = np.array([[essential_features[0] // w, essential_features[0] % w], [last_pixel // w, last_pixel % 4]])[np.newaxis, ...]\n",
    "    critical_pixels_0 = np.vstack([critical_pixels_0, essential_pixels_0])\n",
    "\n",
    "    # 0-homology persistance diagram\n",
    "    pd0 = image[critical_pixels_0[:, :, 0].flatten(), critical_pixels_0[:, :, 1].flatten()].reshape((critical_pixels_0.shape[0], 2))\n",
    "\n",
    "    # 1-homology image critical pixels\n",
    "    try:\n",
    "        critical_pairs_1 = critical_pairs[0][1]\n",
    "    except:\n",
    "        critical_pairs_1 = np.empty((0, 2))\n",
    "    critical_1_ver_ind = critical_pairs_1 // w\n",
    "    critical_1_hor_ind = critical_pairs_1 % w\n",
    "    critical_pixels_1 = np.stack([critical_1_ver_ind, critical_1_hor_ind], axis=2)\n",
    "\n",
    "    # 1-homology persistance diagram\n",
    "    pd1 = image[critical_pixels_1[:, :, 0].flatten(), critical_pixels_1[:, :, 1].flatten()].reshape((critical_pixels_1.shape[0], 2))\n",
    "\n",
    "    return pd0, pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d92055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePersistence(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_conv = self.conv(X)\n",
    "        \n",
    "        peristence_diagrams = []\n",
    "        for i, x_conv in enumerate(X_conv):\n",
    "            pd = persistence_diagram(x_conv[0])\n",
    "            peristence_diagrams.append(pd)\n",
    "        \n",
    "        return peristence_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677abca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent_homology = ImagePersistence()\n",
    "persistent_homology(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6caa553",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDiagram(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(ConvDiagram, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, x):\n",
    "        diagrams = []\n",
    "        for i in range(x.shape[0]):\n",
    "            res = diagram(x[i].flatten(), self.device)\n",
    "            for j in range(len(res)):\n",
    "                diagrams.append(torch.concatenate([res[j], torch.Tensor([[j, i] for _ in range(res[j].shape[0])]).to(self.device)], axis=1))\n",
    "        diagrams = torch.concatenate(diagrams)\n",
    "        return diagrams\n",
    "\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out, seq_size=1024, nhead=2, num_layers=2, dim_feedforward=16):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embeddings = nn.Linear(n_in, n_hidden)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=n_hidden, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(seq_size, n_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embeddings(X)\n",
    "        X = self.transformer(X)\n",
    "        X = X.mean(dim=-1)\n",
    "        X = self.classifier(X)\n",
    "        X = X.softmax(dim=-1)\n",
    "        return X\n",
    "\n",
    "\n",
    "class TopologicalConvTransformer(nn.Module):\n",
    "    def __init__(self, n_in, n_conv, max_sequence, n_diag, n_hidden, n_out, nhead=2, num_layers=2, dim_feedforward=16, device='cuda'):\n",
    "        super(TopologicalConvTransformer, self).__init__()\n",
    "        \n",
    "        self.max_sequence = max_sequence\n",
    "        self.conv1 = nn.Conv2d(n_in, n_conv, 3)\n",
    "        self.conv2 = nn.Conv2d(n_conv, n_conv, 3)\n",
    "        self.conv3 = nn.Conv2d(n_conv, n_conv, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(n_conv)\n",
    "        self.bn2 = nn.BatchNorm2d(n_conv)\n",
    "        self.bn3 = nn.BatchNorm2d(n_conv)\n",
    "        self.diagram = ConvDiagram(device)\n",
    "        self.transformer = Transformer(n_diag, n_hidden, n_out, max_sequence, nhead, num_layers, dim_feedforward)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        result = []\n",
    "        for i in range(xs.shape[0]):\n",
    "            x = xs[i][None, :, :] / 256\n",
    "            x = self.bn1(F.gelu(self.conv1(x)))\n",
    "            #x = self.bn2(F.gelu(self.conv2(x)))\n",
    "            #x = self.bn3(F.gelu(self.conv3(x)))\n",
    "            x = self.diagram(x)\n",
    "            if x.shape[0] > self.max_sequence:\n",
    "                x = x[:self.max_sequence]\n",
    "            x = F.pad(x, (0, 0, 0, self.max_sequence - x.shape[0]), \"constant\", 0)\n",
    "            x = self.transformer(x)\n",
    "            result.append(x[None, :])\n",
    "        result = torch.concatenate(result, axis=0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daa091",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"n_in\": 1,\n",
    " \"n_conv\": 1,\n",
    " \"max_sequence\": 64,\n",
    " \"n_diag\": 4,\n",
    " \"n_hidden\": 32, \"n_out\": 10, \"nhead\": 2, \"num_layers\": 2, \"dim_feedforward\": 16, \"device\": \"cpu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TopologicalConvTransformer(**kwargs)\n",
    "model(images)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_repeats = 1\n",
    "n_epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.002\n",
    "\n",
    "history = np.zeros((n_repeats, n_epochs, 3))\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "for repeat_idx in range(n_repeats):\n",
    "    \n",
    "    # randomness\n",
    "    seed = repeat_idx\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # random state\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # data init\n",
    "    dataset_conv = MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "    dataloader_conv = DataLoader(dataset_conv, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # model init\n",
    "    model = TopologicalConvTransformer(**kwargs)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"{:3} {:6} {:6}\".format(repeat_idx, \"Loss\", \"Acc\"))\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        loss_epoch = []\n",
    "        for batch in dataloader_conv:\n",
    "            loss_batch = criterion(model(batch[0]), batch[1])\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.append(loss_batch.detach())\n",
    "        \n",
    "        loss_epoch_mean = np.array(loss_epoch).mean()\n",
    "        history[repeat_idx,epoch_idx,0] = loss_epoch_mean\n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        for batch in dataloader_conv:\n",
    "            y_hat = model(batch[0]).argmax(dim=1)\n",
    "            correct += int((y_hat == batch[1]).sum())\n",
    "        accuracy_train = correct / len(dataloader_conv.dataset)\n",
    "        history[repeat_idx,epoch_idx,1] = accuracy_train\n",
    "        \n",
    "        print(\"{:3} {:.4f} {:.4f}\".format(epoch_idx, loss_epoch_mean, accuracy_train))\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4b605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
